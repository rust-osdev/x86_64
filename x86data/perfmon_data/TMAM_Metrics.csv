TMAM,Version,3.01,,,Core,,,,,,,,,,,,
,,,,,,Server,,Server,,Server,,Server,,,,,
Key,Level1,Level2,Level3,Level4,SKL,BDX,BDW/BDW-DE,HSX,HSW,IVT,IVB,JKT/SNB-EP,SNB,Locate-with,Count Domain,Metric Description,Threshold
FE,Frontend_Bound,,,,,,,,,,,,IDQ_UOPS_NOT_DELIVERED.CORE / SLOTS,SKL ? FRONTEND_RETIRED.LATENCY_GE_8_PS : N/A,Slots,"This category represents slots fraction where the processor's Frontend undersupplies its Backend. Frontend denotes the first part of the processor core responsible to fetch operations that are executed later on by the Backend part. Within the Frontend, a branch predictor predicts the next address to fetch, cache-lines are fetched from the memory subsystem, parsed into instructions, and lastly decoded into micro-ops (uops). Ideally the Frontend can issue 4 uops every cycle to the Backend. Frontend Bound denotes unutilized issue-slots when there is no Backend stall; i.e. bubbles where Frontend delivered no uops while Backend could have accepted them. For example, stalls due to instruction-cache misses would be categorized under Frontend Bound.",> 0.2
FE,,Frontend_Latency,,,,,#Pipeline_Width * IDQ_UOPS_NOT_DELIVERED.CYCLES_0_UOPS_DELIV.CORE / SLOTS,,,,,,#Pipeline_Width * #Frontend_Latency_Cycles / SLOTS,SKL ? FRONTEND_RETIRED.LATENCY_GE_16_PS;FRONTEND_RETIRED.LATENCY_GE_32_PS : RS_EVENTS.EMPTY_END,Slots,"This metric represents slots fraction the CPU was stalled due to Frontend latency issues.  For example, instruction-cache misses, iTLB misses or fetch stalls after a branch misprediction are categorized under Frontend Latency. In such cases, the Frontend eventually delivers no uops for some period.",> 0.15 & P
FE,,,ICache_Misses,,ICACHE_16B.IFDATA_STALL / CLKS,,,,ICACHE.IFDATA_STALL  / CLKS,,ICACHE.IFETCH_STALL / CLKS - ITLB_Misses,,N/A,SKL ? FRONTEND_RETIRED.L2_MISS_PS;FRONTEND_RETIRED.L1I_MISS_PS : N/A,Clocks,This metric represents cycles fraction the CPU was stalled due to instruction cache misses.,> 0.05 & P
FE,,,ITLB_Misses,,ICACHE_64B.IFTAG_STALL / CLKS,,,,,,,,#ITLB_Miss_Cycles / CLKS,SKL ? FRONTEND_RETIRED.STLB_MISS_PS;FRONTEND_RETIRED.ITLB_MISS_PS : ITLB_MISSES.WALK_COMPLETED,Clocks,This metric represents cycles fraction the CPU was stalled due to instruction TLB misses.,> 0.05 & P
FE,,,Branch_Resteers,,INT_MISC.CLEAR_RESTEER_CYCLES / CLKS,,,,,,,,#Avg_RS_Empty_Period_Clears * ( BR_MISP_RETIRED.ALL_BRANCHES_PS + MACHINE_CLEARS.COUNT + BACLEARS.ANY ) / CLKS,BR_MISP_RETIRED.ALL_BRANCHES_PS,Clocks,"This metric represents cycles fraction the CPU was stalled due to Branch Resteers. Branch Resteers estimates the Frontend delay in fetching operations from corrected path, following all sorts of miss-predicted branches. For example, branchy code with lots of miss-predictions might get categorized under Branch Resteers. Note the value of this node may overlap with its siblings.",> 0.05 & P; $issueB; ~overlap
FE,,,DSB_Switches,,,,,,,,,,DSB2MITE_SWITCHES.PENALTY_CYCLES / CLKS,SKL ? FRONTEND_RETIRED.DSB_MISS_PS : N/A,Clocks,"This metric represents cycles fraction the CPU was stalled due to switches from DSB to MITE pipelines. The DSB (decoded i-cache, introduced with the Sandy Bridge microarchitecture) pipeline has shorter latency and delivered higher bandwidth than the MITE (legacy instruction decode pipeline). Switching between the two pipelines can cause penalties. This metric estimates when such penalty can be exposed. Optimizing for better DSB hit rate may be considered.",> 0.05 & P
FE,,,MS_Switches,,,,,,,,,,#MS_Switches_Cost * IDQ.MS_SWITCHES / CLKS,IDQ.MS_SWITCHES,Clocks,"This metric estimates the fraction of cycles when the CPU was stalled due to switches of uop delivery to the Microcode Sequencer (MS). Commonly used instructions are optimized for delivery by the DSB or MITE pipelines. Certain operations cannot be handled natively by the execution pipeline, and must be performed by microcode (small programs injected into the execution stream). Switching to the MS too often can negatively impact performance. The MS is designated to deliver long uop flows required by CISC instructions like CPUID, or uncommon conditions like Floating Point Assists when dealing with Denormals.",> 0.05 & P; $issueMS
FE,,Frontend_Bandwidth,,,,,,,,,,,Frontend_Bound - Frontend_Latency,SKL ? FRONTEND_RETIRED.LATENCY_GE_2_BUBBLES_GE_1_PS : N/A,Slots,"This metric represents slots fraction the CPU was stalled due to Frontend bandwidth issues.  For example, inefficiencies at the instruction decoders, or code restrictions for caching in the DSB (decoded uops cache) are categorized under Frontend Bandwidth. In such cases, the Frontend typically delivers non-optimal amount of uops to the Backend (less than four).",> 0.1 & (IPC > 2.0) & P
BAD,Bad_Speculation,,,,,,,,,,,,( UOPS_ISSUED.ANY - UOPS_RETIRED.RETIRE_SLOTS + #Pipeline_Width * #Recovery_Cycles ) / SLOTS,INT_MISC.RECOVERY_CYCLES,Slots,"This category represents slots fraction wasted due to incorrect speculations. This include slots used to issue uops that do not eventually get retired and slots for which the issue-pipeline was blocked due to recovery from earlier incorrect speculation. For example, wasted work due to miss-predicted branches are categorized under Bad Speculation category. Incorrect data speculation followed by Memory Ordering Nukes is another example.",> 0.1; $issueB
BAD,,Branch_Mispredicts,,,,,,,,,,,#Mispred_Clears_Fraction * Bad_Speculation,BR_MISP_RETIRED.ALL_BRANCHES_PS,Slots,"This metric represents slots fraction the CPU has wasted due to Branch Misprediction.  These slots are either wasted by uops fetched from an incorrectly speculated program path, or stalls when the out-of-order part of the machine needs to recover its state from a speculative path.",> 0.05 & P
BAD,,Machine_Clears,,,,,,,,,,,Bad_Speculation - Branch_Mispredicts,MACHINE_CLEARS.COUNT,Slots,"This metric represents slots fraction the CPU has wasted due to Machine Clears.  These slots are either wasted by uops fetched prior to the clear, or stalls the out-of-order portion of the machine needs to recover its state after the clear. For example, this can happen due to memory ordering Nukes (e.g. Memory Disambiguation) or Self-Modifying-Code (SMC) nukes.",> 0.05 & P
BE,Backend_Bound,,,,,,,,,,,,1 - ( Frontend_Bound + Bad_Speculation + Retiring ),,Slots,"This category represents slots fraction where no uops are being delivered due to a lack of required resources for accepting new uops in the Backend. Backend is the portion of the processor core where the out-of-order scheduler dispatches ready uops into their respective execution units, and once completed these uops get retired according to program order. For example, stalls due to data-cache misses or stalls due to the divider unit being overloaded are both categorized under Backend Bound. Backend Bound is further divided into two main categories: Memory Bound and Core Bound.",> 0.2
BE/Mem,,Memory_Bound,,,,,,,,,,,#Memory_Bound_Fraction * Backend_Bound,,Slots,"This metric represents slots fraction the Memory subsystem within the Backend was a bottleneck.  Memory Bound estimates slots fraction where pipeline is likely stalled due to demand load or store instructions. This accounts mainly for (1) non-completed in-flight memory demand loads which coincides with execution units starvation, in addition to (2) cases where stores could impose backpressure on the pipeline when many of them get buffered at the same time (less common out of the two).",> 0.2 & P
BE/Mem,,,L1_Bound,,,,( CYCLE_ACTIVITY.STALLS_MEM_ANY - CYCLE_ACTIVITY.STALLS_L1D_MISS ) / CLKS,,,,( #STALLS_MEM_ANY - CYCLE_ACTIVITY.STALLS_L1D_PENDING ) / CLKS,,N/A,SKL ? MEM_LOAD_RETIRED.L1_HIT_PS;MEM_LOAD_RETIRED.FB_HIT_PS : MEM_LOAD_UOPS_RETIRED.L1_HIT_PS;MEM_LOAD_UOPS_RETIRED.HIT_LFB_PS,Clocks,"This metric estimates how often the CPU was stalled without loads missing the L1 data cache.  The L1 data cache typically has the shortest latency.  However, in certain cases like loads blocked on older stores, a load might suffer due to high latency even though it is being satisfied by the L1. Another example is loads who miss in the TLB. These cases are characterized by execution unit stalls, while some non-completed demand load lives in the machine without having that demand load missing the L1 cache.",(> 0.07 & P) | DTLB_Load
BE/Mem,,,,DTLB_Load,( #Mem_STLB_Hit_Cost * DTLB_LOAD_MISSES.STLB_HIT + DTLB_LOAD_MISSES.WALK_ACTIVE ) / CLKS,,( #Mem_STLB_Hit_Cost * DTLB_LOAD_MISSES.STLB_HIT + DTLB_LOAD_MISSES.WALK_DURATION:c1 ) / CLKS,,,,,,( #Mem_STLB_Hit_Cost * DTLB_LOAD_MISSES.STLB_HIT + DTLB_LOAD_MISSES.WALK_DURATION ) / CLKS,SKL ? MEM_INST_RETIRED.STLB_MISS_LOADS_PS : MEM_UOPS_RETIRED.STLB_MISS_LOADS_PS,Clocks,This metric represents cycles fraction where the TLB was missed by load instructions. TLBs (Translation Look-aside Buffers) are processor caches for recently used entries out of the Page Tables that are used to map virtual- to physical-addresses by the operating system. This metric estimates the performance penalty paid by demand loads when missing the first-level data TLB (DTLB). This includes hitting in the second-level TLB (STLB) as well as performing a hardware page walk on an STLB miss.,> 0.1 & P
BE/Mem,,,L2_Bound,,,,( CYCLE_ACTIVITY.STALLS_L1D_MISS - CYCLE_ACTIVITY.STALLS_L2_MISS ) / CLKS,,,,( CYCLE_ACTIVITY.STALLS_L1D_PENDING - CYCLE_ACTIVITY.STALLS_L2_PENDING ) / CLKS,,N/A,SKL ? MEM_LOAD_RETIRED.L2_HIT_PS : MEM_LOAD_UOPS_RETIRED.L2_HIT_PS,Clocks,This metric estimates how often the CPU was stalled due to L2 cache accesses by loads.  Avoiding cache misses (i.e. L1 misses/L2 hits) can improve the latency and increase performance.,> 0.03 & P
BE/Mem,,,L3_Bound,,( CYCLE_ACTIVITY.STALLS_L2_MISS - CYCLE_ACTIVITY.STALLS_L3_MISS ) / CLKS,,#Mem_L3_Hit_Fraction * CYCLE_ACTIVITY.STALLS_L2_MISS / CLKS,,,,,,#Mem_L3_Hit_Fraction * CYCLE_ACTIVITY.STALLS_L2_PENDING / CLKS,SKL ? MEM_LOAD_RETIRED.L3_HIT_PS : IVB/IVT/SNB/JKT ? MEM_LOAD_UOPS_RETIRED.LLC_HIT_PS : MEM_LOAD_UOPS_RETIRED.L3_HIT_PS,Clocks,This metric estimates how often the CPU was stalled due to loads accesses to L3 cache or contended with a sibling Core.  Avoiding cache misses (i.e. L2 misses/L3 hits) can improve the latency and increase performance.,> 0.1 & P
BE/Mem,,,MEM_Bound,,CYCLE_ACTIVITY.STALLS_L3_MISS / CLKS,,(1 - #Mem_L3_Hit_Fraction) * CYCLE_ACTIVITY.STALLS_L2_MISS / CLKS,,,,,,(1 - #Mem_L3_Hit_Fraction) * CYCLE_ACTIVITY.STALLS_L2_PENDING / CLKS,SKL ? MEM_LOAD_RETIRED.L3_MISS_PS : IVB/IVT/JKT ? MEM_LOAD_UOPS_RETIRED.LLC_MISS_PS : SNB ? MEM_LOAD_UOPS_MISC_RETIRED.LLC_MISS_PS : MEM_LOAD_UOPS_RETIRED.L3_MISS_PS,Clocks,This metric estimates how often the CPU was stalled on accesses to external memory (DRAM) by loads. Better caching can improve the latency and increase performance.,> 0.1 & P
BE/Mem,,,,MEM_Bandwidth,#ORO_L3M_Demand_DRD_C6 / CLKS,,,,,,,,#ORO_Demand_DRD_C6 / CLKS,,Clocks,This metric estimates cycles fraction where the performance was likely hurt due to approaching bandwidth limits of external main (DRAM).  This metric does not aggregate requests from other threads/cores/sockets (see Uncore counters for that).,> 0.1 & P
BE/Mem,,,,MEM_Latency,( #ORO_L3M_Demand_DRD_C1 - #ORO_L3M_Demand_DRD_C6 ) / CLKS,,,,,,,,( #ORO_Demand_DRD_C1 - #ORO_Demand_DRD_C6 ) / CLKS,,Clocks,This metric estimates cycles fraction where the performance was likely hurt due to latency from external memory (DRAM).  This metric does not aggregate requests from other threads/cores/sockets (see Uncore counters for that).,> 0.1 & P
BE/Mem,,,Stores_Bound,,EXE_ACTIVITY.BOUND_ON_STORES / CLKS,,( RESOURCE_STALLS.SB -  CYCLE_ACTIVITY.STALLS_MEM_ANY ) / CLKS,,,,,,( RESOURCE_STALLS.SB -  #STALLS_MEM_ANY ) / CLKS,SKL ? MEM_INST_RETIRED.ALL_STORES_PS : MEM_UOPS_RETIRED.ALL_STORES_PS,Clocks,This metric estimates how often CPU was stalled  due to store memory accesses. Even though store accesses do not typically stall out-of-order CPUs; there are few cases where stores can lead to actual stalls. This metric will be flagged should any of these cases be a bottleneck.,> 0.2 & P
BE/Core,,Core_Bound,,,,,,,,,,,Backend_Bound - Memory_Bound,,Slots,"This metric represents slots fraction where Core non-memory issues were of a bottleneck.  Shortage in hardware compute resources, or dependencies in software's instructions are both categorized under Core Bound. Hence it may indicate the machine ran out of an out-of-order resource, certain execution units are overloaded or dependencies in program's data- or instruction-flow are limiting the performance (e.g. FP-chained long-latency arithmetic operations).",> 0.2 & P
BE/Core,,,Divider,,ARITH.DIVIDER_ACTIVE / CLKS,,ARITH.FPU_DIV_ACTIVE / CORE_CLKS,,10 * ARITH.DIVIDER_UOPS / CORE_CLKS,,,,ARITH.FPU_DIV_ACTIVE / CORE_CLKS,SKL ? ARITH.DIVIDER_ACTIVE : HSW/HSX ? ARITH.DIVIDER_UOPS : ARITH.FPU_DIV_ACTIVE,CoreClocks,"This metric represents cycles fraction where the Divider unit was active. Divide and square root instructions are performed by the Divider unit and can take considerably longer latency than integer or Floating Point addition, subtraction, or multiplication.",> 0.2 & P
BE/Core,,,Ports_Utilization,,( #Backend_Bound_Cycles - CYCLE_ACTIVITY.STALLS_MEM_ANY - EXE_ACTIVITY.BOUND_ON_STORES ) / CLKS,,( #Backend_Bound_Cycles - RESOURCE_STALLS.SB -  CYCLE_ACTIVITY.STALLS_MEM_ANY ) / CLKS,,,,,,( #Backend_Bound_Cycles - RESOURCE_STALLS.SB -  #STALLS_MEM_ANY ) / CLKS,,Clocks,"This metric estimates cycles fraction the CPU performance was potentially limited due to Core computation issues (non divider-related).  Two distinct categories can be attributed into this metric: (1) heavy data-dependency among contiguous instructions would manifest in this metric - such cases are often referred to as low Instruction Level Parallelism (ILP). (2) Contention on some hardware execution unit other than Divider. For example, when there are too many multiply operations.",> 0.2 & P
RET,Retiring,,,,,,,,,,,,UOPS_RETIRED.RETIRE_SLOTS / SLOTS,,Slots,"This category represents slots fraction utilized by useful work i.e. allocated uops that eventually get retired. Ideally, all pipeline slots would be attributed to the Retiring category.  Retiring of 100% would indicate the maximum 4 uops retired per cycle has been achieved.  Maximizing Retiring typically increases the Instruction-Per-Cycle metric.
Note that a high Retiring value does not necessary mean there is no room for more performance.  For example, Microcode assists are categorized under Retiring. They hurt performance and can often be avoided. ",(> 0.7 | Microcode_Sequencer)
RET,,Base,,,,,,,,,,,Retiring - Microcode_Sequencer,INST_RETIRED.PREC_DIST,Slots,"This metric represents slots fraction where the CPU was retiring regular uops (ones not originated from the microcode-sequencer). This correlates with total number of instructions used by the program. A uops-per-instruction ratio of 1 should be expected. While this is the most desirable of the top 4 categories, high values does not necessarily mean there no room for performance optimizations.",> 0.6 & P
RET,,,FP_Arith,,,,FP_Scalar + FP_Vector,,N/A,,,,FP_Scalar + FP_Vector,,Uops,This metric represents overall arithmetic floating-point (FP) uops fraction the CPU has executed (retired),> 0.2 & P
RET,,,,FP_Scalar,,,( FP_ARITH_INST_RETIRED.SCALAR_SINGLE + FP_ARITH_INST_RETIRED.SCALAR_DOUBLE ) / UOPS_RETIRED.RETIRE_SLOTS,,N/A,,( FP_COMP_OPS_EXE.SSE_SCALAR_SINGLE + FP_COMP_OPS_EXE.SSE_SCALAR_DOUBLE ) / UOPS_EXECUTED.THREAD,,( FP_COMP_OPS_EXE.SSE_SCALAR_SINGLE + FP_COMP_OPS_EXE.SSE_SCALAR_DOUBLE ) / UOPS_DISPATCHED.THREAD,,Uops,This metric represents arithmetic floating-point (FP) scalar uops fraction the CPU has executed (retired).,> 0.1 & P
RET,,,,FP_Vector,,,( FP_ARITH_INST_RETIRED.128B_PACKED_DOUBLE + FP_ARITH_INST_RETIRED.128B_PACKED_SINGLE + FP_ARITH_INST_RETIRED.256B_PACKED_DOUBLE + FP_ARITH_INST_RETIRED.256B_PACKED_SINGLE ) / UOPS_RETIRED.RETIRE_SLOTS,,N/A,,( FP_COMP_OPS_EXE.SSE_PACKED_DOUBLE + FP_COMP_OPS_EXE.SSE_PACKED_SINGLE + SIMD_FP_256.PACKED_SINGLE + SIMD_FP_256.PACKED_DOUBLE ) / UOPS_EXECUTED.THREAD,,( FP_COMP_OPS_EXE.SSE_PACKED_DOUBLE + FP_COMP_OPS_EXE.SSE_PACKED_SINGLE + SIMD_FP_256.PACKED_SINGLE + SIMD_FP_256.PACKED_DOUBLE ) / UOPS_DISPATCHED.THREAD,,Uops,This metric represents arithmetic floating-point (FP) vector uops fraction the CPU has executed (retired) aggregated across all vector widths.,> 0.2 & P
RET,,,Other,,,,1 - FP_Arith,,N/A,,,,1 - FP_Arith,,Uops,"This metric represents non-floating-point (FP) uop fraction the CPU has executed. If you application has no FP operations and performs with decent IPC (Instructions Per Cycle), this node will likely be biggest fraction.",> 0.3 & P
RET,,Microcode_Sequencer,,,,,,,,,,,#Retire_Uop_Fraction * IDQ.MS_UOPS / SLOTS,IDQ.MS_UOPS,Slots,"This metric represents slots fraction the CPU was retiring uops fetched by the Microcode Sequencer (MS) unit.  The MS is used for CISC instructions not supported by the default decoders (like repeat move strings, or CPUID), or by microcode assists used to address some operation modes (like in Floating Point assists). These cases can often be avoided.",> 0.05; $issueMS
Info,IPC,,,,,,,,,,,,INST_RETIRED.ANY / CLKS,,Metric/5,Instructions Per Cycle (per logical thread),
SW_Info,CPI,,,,,,,,,,,,1/IPC,,Metric,Cycles Per Instruction (threaded),
Info,CoreIPC,,,,,,,,,,,,INST_RETIRED.ANY / CORE_CLKS,,CoreMetric/5,Instructions Per Cycle (per physical core),
Info,UPI,,,,,,,,,,,,UOPS_RETIRED.RETIRE_SLOTS / INST_RETIRED.ANY,,Metric/2,Uops Per Instruction,
Info,IFetch_Line_Utilization,,,,"min( 1 , UOPS_ISSUED.ANY / (UPI * 64 * ( ICACHE_64B.IFTAG_HIT + ICACHE_64B.IFTAG_MISS ) / 4.1) )",,,,,,,,"min( 1 , UOPS_ISSUED.ANY / ( UPI * 32 * ( ICACHE.HIT + ICACHE.MISSES ) / 4) )",,Metric/1,Rough Estimation of fraction of fetched lines bytes consumed by program instructions,< 0.5
Info,DSB_Coverage,,,,,,,,,,,,( IDQ.DSB_UOPS + LSD.UOPS ) / ( IDQ.DSB_UOPS + LSD.UOPS + IDQ.MITE_UOPS + IDQ.MS_UOPS ),,Metric/1,Fraction of Uops delivered by the DSB (decoded instructions cache),
Info,ILP,,,,,,UOPS_EXECUTED.THREAD / #Execute_Cycles,,( UOPS_EXECUTED.CORE / 2 / #Execute_Cycles ) if #SMT_on else UOPS_EXECUTED.CORE / #Execute_Cycles,,UOPS_EXECUTED.THREAD / #Execute_Cycles,,UOPS_DISPATCHED.THREAD / #Execute_Cycles,,Metric/10,Instruction-Level-Parallelism (average number of uops executed when there is at least 1 uop executed),
SW_Info,GFLOPs,,,,,,#FLOP_Count / #OneBillion / #DurationTimeInSeconds#,,N/A ,,,,#FLOP_Count / #OneBillion / #DurationTimeInSeconds#,,Metric/100,Giga Floating Point Operations Per Second,
SW_Info,CPU_Utilization,,,,,,,,,,,,CPU_CLK_UNHALTED.REF_TSC / TSC,,Metric/100,Average CPU Utilization,
SW_Info,Turbo_Utilization,,,,,,,,,,,,CLKS / CPU_CLK_UNHALTED.REF_TSC,,CoreMetric/10,Average Frequency Utilization relative nominal frequency,
SW_Info,SMT_2T_Utilization,,,,,,,,,,,,1 - CPU_CLK_THREAD_UNHALTED.ONE_THREAD_ACTIVE / ( CPU_CLK_THREAD_UNHALTED.REF_XCLK_ANY / 2 ) if #SMT_on else 0,,Metric/1,Fraction of cycles where both hardware threads were active,
SW_Info,Kernel_Utilization,,,,,,,,,,,,CPU_CLK_UNHALTED.REF_TSC:sup / CPU_CLK_UNHALTED.REF_TSC,,Metric/1,Fraction of cycles spent in Kernel mode,< 0.1
SW_Info,MEM_BW_GBs,,,,,,,,,,,64 * ( UNC_M_CAS_COUNT.RD + UNC_M_CAS_COUNT.WR ) / #OneMillion / #DurationTimeInSeconds# / 1000,64 * ( UNC_ARB_TRK_REQUESTS.ALL + UNC_ARB_COH_TRK_REQUESTS.ALL ) / #OneMillion / #DurationTimeInSeconds# / 1000,,Metric/100,Average external Memory Bandwidth Use for reads and writes [GB / sec],
SW_Info,MUX,,,,,,,,,,,,CPU_CLK_UNHALTED.THREAD_P / CPU_CLK_UNHALTED.THREAD,,Clocks,PerfMon Event Multiplexing accuracy indicator,
Info,CLKS,,,,,,,,,,,,CPU_CLK_UNHALTED.THREAD,,Count,Per-thread actual clocks when the thread is active,
Info,CORE_CLKS,,,,,,,,,,,,( CPU_CLK_UNHALTED.THREAD_ANY / 2 ) if #SMT_on else CLKS,,Count,Core actual clocks when any thread is active on the physical core,
SW_Info,Time,,,,,,,,,,,,#DurationTimeInSeconds#,,Count,Run duration time in seconds,< 1
Aux,#FLOP_Count,,,,,,( 1*( FP_ARITH_INST_RETIRED.SCALAR_SINGLE + FP_ARITH_INST_RETIRED.SCALAR_DOUBLE ) + 2* FP_ARITH_INST_RETIRED.128B_PACKED_DOUBLE + 4*( FP_ARITH_INST_RETIRED.128B_PACKED_SINGLE + FP_ARITH_INST_RETIRED.256B_PACKED_DOUBLE ) + 8* FP_ARITH_INST_RETIRED.256B_PACKED_SINGLE ),,N/A,,,,( 1*( FP_COMP_OPS_EXE.SSE_SCALAR_SINGLE + FP_COMP_OPS_EXE.SSE_SCALAR_DOUBLE ) + 2* FP_COMP_OPS_EXE.SSE_PACKED_DOUBLE + 4*( FP_COMP_OPS_EXE.SSE_PACKED_SINGLE + SIMD_FP_256.PACKED_DOUBLE ) + 8* SIMD_FP_256.PACKED_SINGLE ),,Count,Floating Point computational (arithmetic) Operations Count,
Aux,#Recovery_Cycles,,,,,,,,,,,,( INT_MISC.RECOVERY_CYCLES_ANY / 2 ) if #SMT_on else INT_MISC.RECOVERY_CYCLES,,Count,,
Aux,#Execute_Cycles,,,,( UOPS_EXECUTED.CORE_CYCLES_GE_1 / 2) if #SMT_on else UOPS_EXECUTED.CORE_CYCLES_GE_1,,( UOPS_EXECUTED.CORE:c1 / 2) if #SMT_on else UOPS_EXECUTED.CYCLES_GE_1_UOP_EXEC,,( UOPS_EXECUTED.CORE:c1 / 2) if #SMT_on else UOPS_EXECUTED.CORE:c1,,( UOPS_EXECUTED.CORE:c1 / 2) if #SMT_on else UOPS_EXECUTED.CYCLES_GE_1_UOP_EXEC,,( UOPS_DISPATCHED.CORE:c1 / 2) if #SMT_on else UOPS_DISPATCHED.CORE:c1,,Count,,
Aux,#ITLB_Miss_Cycles,,,,N/A,,( #Mem_STLB_Hit_Cost * ITLB_MISSES.STLB_HIT + ITLB_MISSES.WALK_DURATION:c1 ),,,,,,( #Mem_STLB_Hit_Cost * ITLB_MISSES.STLB_HIT + ITLB_MISSES.WALK_DURATION ),,Count,,
Aux,#Frontend_Latency_Cycles,,,,,,N/A,,,,,,"min( CPU_CLK_UNHALTED.THREAD , IDQ_UOPS_NOT_DELIVERED.CYCLES_0_UOPS_DELIV.CORE )",,Count,,
Aux,#STALLS_MEM_ANY,,,,,,N/A,,,,"min( CPU_CLK_UNHALTED.THREAD , CYCLE_ACTIVITY.STALLS_LDM_PENDING )",,"min( CPU_CLK_UNHALTED.THREAD , CYCLE_ACTIVITY.STALLS_L1D_PENDING )",,Count,,
Aux,#STALLS_TOTAL,,,,,,N/A,,,,"min( CPU_CLK_UNHALTED.THREAD , CYCLE_ACTIVITY.CYCLES_NO_EXECUTE )",,"min( CPU_CLK_UNHALTED.THREAD , CYCLE_ACTIVITY.CYCLES_NO_DISPATCH )",,Count,,
Aux,#ORO_Demand_DRD_C1,,,,,,,,,,,,"min( CPU_CLK_UNHALTED.THREAD , OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_DEMAND_DATA_RD )",,Count,,
Aux,#ORO_Demand_DRD_C6,,,,"min( CPU_CLK_UNHALTED.THREAD , OFFCORE_REQUESTS_OUTSTANDING.DEMAND_DATA_RD_GE_6 )",,,,,,,,"min( CPU_CLK_UNHALTED.THREAD , OFFCORE_REQUESTS_OUTSTANDING.DEMAND_DATA_RD:c6 )",,Count,,
Aux,#ORO_L3M_Demand_DRD_C1,,,,"min( CPU_CLK_UNHALTED.THREAD , OFFCORE_REQUESTS_OUTSTANDING.CYCLES_WITH_L3_MISS_DEMAND_DATA_RD )",,,,,,,,N/A,,Count,,
Aux,#ORO_L3M_Demand_DRD_C6,,,,"min( CPU_CLK_UNHALTED.THREAD , OFFCORE_REQUESTS_OUTSTANDING.L3_MISS_DEMAND_DATA_RD_GE_6 )",,,,,,,,N/A,,Count,,
Aux,#Few_Uops_Executed_Threshold,,,,EXE_ACTIVITY.2_PORTS_UTIL if ( IPC > 1.25 ) else 0,,UOPS_EXECUTED.CYCLES_GE_3_UOPS_EXEC if ( IPC > 1.25 ) else UOPS_EXECUTED.CYCLES_GE_2_UOPS_EXEC,,UOPS_EXECUTED.CORE:c3 if ( IPC > 1.25 ) else UOPS_EXECUTED.CORE:c2,,UOPS_EXECUTED.CYCLES_GE_3_UOPS_EXEC if ( IPC > 1.25 ) else UOPS_EXECUTED.CYCLES_GE_2_UOPS_EXEC,,UOPS_DISPATCHED.THREAD:c3 if ( IPC > 1.25 ) else UOPS_DISPATCHED.THREAD:c2,,Count,,
Aux,#Backend_Bound_Cycles,,,,( EXE_ACTIVITY.EXE_BOUND_0_PORTS + EXE_ACTIVITY.1_PORTS_UTIL + #Few_Uops_Executed_Threshold ) + ( CYCLE_ACTIVITY.STALLS_MEM_ANY + EXE_ACTIVITY.BOUND_ON_STORES ) ,,( CYCLE_ACTIVITY.STALLS_TOTAL + UOPS_EXECUTED.CYCLES_GE_1_UOP_EXEC - #Few_Uops_Executed_Threshold - RS_EVENTS.EMPTY_CYCLES + RESOURCE_STALLS.SB ),,( #STALLS_TOTAL + (UOPS_EXECUTED.CORE:c1 - #Few_Uops_Executed_Threshold)/2 - RS_EVENTS.EMPTY_CYCLES + RESOURCE_STALLS.SB ) if #SMT_on else ( #STALLS_TOTAL + UOPS_EXECUTED.CORE:c1 - #Few_Uops_Executed_Threshold - RS_EVENTS.EMPTY_CYCLES + RESOURCE_STALLS.SB ),,( #STALLS_TOTAL + UOPS_EXECUTED.CYCLES_GE_1_UOP_EXEC - #Few_Uops_Executed_Threshold - RS_EVENTS.EMPTY_CYCLES + RESOURCE_STALLS.SB ),,( #STALLS_TOTAL + UOPS_DISPATCHED.THREAD:c1 - #Few_Uops_Executed_Threshold - RS_EVENTS.EMPTY_CYCLES + RESOURCE_STALLS.SB ),,Count,,
Aux,#Memory_Bound_Fraction,,,,( CYCLE_ACTIVITY.STALLS_MEM_ANY + EXE_ACTIVITY.BOUND_ON_STORES ) / #Backend_Bound_Cycles,,( CYCLE_ACTIVITY.STALLS_MEM_ANY + RESOURCE_STALLS.SB ) / #Backend_Bound_Cycles,,,,,,( #STALLS_MEM_ANY + RESOURCE_STALLS.SB ) / #Backend_Bound_Cycles,,Fraction,,
Aux,#Mem_L3_Hit_Fraction,,,,N/A,,,,MEM_LOAD_UOPS_RETIRED.L3_HIT_PS / ( MEM_LOAD_UOPS_RETIRED.L3_HIT_PS + #Mem_L3_Weight * MEM_LOAD_UOPS_RETIRED.L3_MISS_PS ),,MEM_LOAD_UOPS_RETIRED.LLC_HIT_PS / ( MEM_LOAD_UOPS_RETIRED.LLC_HIT_PS + #Mem_L3_Weight * MEM_LOAD_UOPS_RETIRED.LLC_MISS_PS ),MEM_LOAD_UOPS_RETIRED.LLC_HIT_PS / ( MEM_LOAD_UOPS_RETIRED.LLC_HIT_PS + #Mem_L3_Weight * MEM_LOAD_UOPS_RETIRED.LLC_MISS_PS ),MEM_LOAD_UOPS_RETIRED.LLC_HIT_PS / ( MEM_LOAD_UOPS_RETIRED.LLC_HIT_PS + #Mem_L3_Weight * MEM_LOAD_UOPS_MISC_RETIRED.LLC_MISS_PS ),,Fraction,,
Aux,#Mispred_Clears_Fraction,,,,,,,,,,,,BR_MISP_RETIRED.ALL_BRANCHES_PS / ( BR_MISP_RETIRED.ALL_BRANCHES_PS + MACHINE_CLEARS.COUNT ),,Fraction,,
Aux,#Avg_RS_Empty_Period_Clears,,,,N/A,,,,( RS_EVENTS.EMPTY_CYCLES - ICACHE.IFDATA_STALL  - #ITLB_Miss_Cycles ) / RS_EVENTS.EMPTY_END,,( RS_EVENTS.EMPTY_CYCLES - ICACHE.IFETCH_STALL ) / RS_EVENTS.EMPTY_END,,( RS_EVENTS.EMPTY_CYCLES - #ITLB_Miss_Cycles ) / RS_EVENTS.EMPTY_END,,Metric,,
Aux,#Retire_Uop_Fraction,,,,,,,,,,,,UOPS_RETIRED.RETIRE_SLOTS / UOPS_ISSUED.ANY,,Fraction,,
Aux,SLOTS,,,,,,,,,,,,#Pipeline_Width*CORE_CLKS,,Count,Total issue-pipeline slots,
Aux,#Pipeline_Width,,,,,,,,,,,,4,,Constant,,
Aux,#Mem_L3_Weight,,,,N/A,,,,,,,,7,,Constant,,
Aux,#Mem_STLB_Hit_Cost,,,,,,,,,,,,7,,Constant,,
Aux,#MS_Switches_Cost,,,,,,,,2,,,,3,,Constant,,
Aux,#OneMillion,,,,,,,,,,,,1000000,,Constant,,
Aux,#OneBillion,,,,,,,,,,,,1000000000,,Constant,,
